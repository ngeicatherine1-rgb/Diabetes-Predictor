{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95298a27",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ad2cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"✓ All libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36d7b856",
   "metadata": {},
   "source": [
    "## 2. Create Sample Dataset\n",
    "\n",
    "If you don't have the real dataset, we'll create a synthetic one for demonstration."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc7dd792",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90441426",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "}\n",
    "# Create synthetic diabetes dataset\n",
    "np.random.seed(42)\n",
    "\n",
    "n_samples = 768\n",
    "\n",
    "data = {\n",
    "    'Pregnancies': np.random.randint(0, 17, n_samples),\n",
    "    'Glucose': np.random.randint(44, 200, n_samples),\n",
    "    'BloodPressure': np.random.randint(24, 122, n_samples),\n",
    "    'SkinThickness': np.random.randint(0, 99, n_samples),\n",
    "    'Insulin': np.random.randint(0, 846, n_samples),\n",
    "    'BMI': np.random.uniform(18.2, 67.1, n_samples),\n",
    "    'DiabetesPedigreeFunction': np.random.uniform(0.078, 2.42, n_samples),\n",
    "    'Age': np.random.randint(21, 81, n_samples),\n",
    "# Create target variable with some correlation to features\n",
    "df = pd.DataFrame(data)\n",
    "df['Outcome'] = ((df['Glucose'] > 125) & (df['BMI'] > 30)).astype(int)\n",
    "\n",
    "# Add some noise\n",
    "noise_idx = np.random.choice(len(df), 150, replace=False)\n",
    "df.loc[noise_idx, 'Outcome'] = 1 - df.loc[noise_idx, 'Outcome']\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"\\nFirst 5 rows:\")\n",
    "print(df.head())\n",
    "print(f\"\\nDataset Statistics:\")\n",
    "print(df.describe())\n",
    "print(f\"\\nTarget distribution:\")\n",
    "print(df['Outcome'].value_counts())\n",
    "print(f\"\\nDiabetes prevalence: {df['Outcome'].mean()*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "955597b9",
   "metadata": {},
   "source": [
    "## 3. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdfc9459",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle missing values (if any)\n",
    "print(f\"Missing values before cleaning:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Fill missing values with mean\n",
    "df_filled = df.fillna(df.mean())\n",
    "print(f\"\\nMissing values after cleaning:\")\n",
    "print(df_filled.isnull().sum().sum())\n",
    "\n",
    "# Separate features and target\n",
    "X = df_filled.drop('Outcome', axis=1)\n",
    "y = df_filled['Outcome']\n",
    "\n",
    "print(f\"\\nFeatures shape: {X.shape}\")\n",
    "print(f\"Target shape: {y.shape}\")\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"\\nTraining set size: {X_train.shape[0]} samples\")\n",
    "print(f\"Testing set size: {X_test.shape[0]} samples\")\n",
    "\n",
    "# Scale features using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(f\"\\n✓ Scaling applied\")\n",
    "print(f\"Mean of scaled training features: {X_train_scaled.mean():.6f}\")\n",
    "print(f\"Std of scaled training features: {X_train_scaled.std():.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db5ba50b",
   "metadata": {},
   "source": [
    "## 4. Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c6bd35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Logistic Regression\n",
    "print(\"Training Logistic Regression...\")\n",
    "lr_model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "lr_model.fit(X_train_scaled, y_train)\n",
    "print(\"✓ Logistic Regression trained\")\n",
    "\n",
    "# Train Random Forest\n",
    "print(\"\\nTraining Random Forest...\")\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "rf_model.fit(X_train_scaled, y_train)\n",
    "print(\"✓ Random Forest trained\")\n",
    "\n",
    "# Save models\n",
    "joblib.dump(lr_model, '../models/logistic_reg.pkl')\n",
    "joblib.dump(rf_model, '../models/random_forest.pkl')\n",
    "joblib.dump(scaler, '../models/scaler.pkl')\n",
    "print(\"\\n✓ Models saved to models/ directory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9888ecff",
   "metadata": {},
   "source": [
    "## 5. Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ebf59e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "lr_pred = lr_model.predict(X_test_scaled)\n",
    "rf_pred = rf_model.predict(X_test_scaled)\n",
    "\n",
    "# Get prediction probabilities\n",
    "lr_proba = lr_model.predict_proba(X_test_scaled)\n",
    "rf_proba = rf_model.predict_proba(X_test_scaled)\n",
    "\n",
    "# Evaluation metrics\n",
    "def evaluate_model(y_true, y_pred, model_name):\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred, zero_division=0)\n",
    "    recall = recall_score(y_true, y_pred, zero_division=0)\n",
    "    f1 = f1_score(y_true, y_pred, zero_division=0)\n",
    "    \n",
    "    print(f\"\\n{model_name} Metrics:\")\n",
    "    print(f\"  Accuracy:  {accuracy:.4f}\")\n",
    "    print(f\"  Precision: {precision:.4f}\")\n",
    "    print(f\"  Recall:    {recall:.4f}\")\n",
    "    print(f\"  F1-Score:  {f1:.4f}\")\n",
    "    \n",
    "    return {\n",
    "        'Accuracy': accuracy,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'F1-Score': f1\n",
    "    }\n",
    "\n",
    "# Evaluate both models\n",
    "lr_metrics = evaluate_model(y_test, lr_pred, \"Logistic Regression\")\n",
    "rf_metrics = evaluate_model(y_test, rf_pred, \"Random Forest\")\n",
    "\n",
    "# Display confusion matrices\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Logistic Regression Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, lr_pred))\n",
    "\n",
    "print(\"\\nRandom Forest Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, rf_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c948e752",
   "metadata": {},
   "source": [
    "## 6. Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d21836a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrices\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# Logistic Regression CM\n",
    "cm_lr = confusion_matrix(y_test, lr_pred)\n",
    "sns.heatmap(cm_lr, annot=True, fmt='d', cmap='Blues', ax=axes[0], cbar=False)\n",
    "axes[0].set_title('Logistic Regression Confusion Matrix')\n",
    "axes[0].set_ylabel('True Label')\n",
    "axes[0].set_xlabel('Predicted Label')\n",
    "\n",
    "# Random Forest CM\n",
    "cm_rf = confusion_matrix(y_test, rf_pred)\n",
    "sns.heatmap(cm_rf, annot=True, fmt='d', cmap='Greens', ax=axes[1], cbar=False)\n",
    "axes[1].set_title('Random Forest Confusion Matrix')\n",
    "axes[1].set_ylabel('True Label')\n",
    "axes[1].set_xlabel('Predicted Label')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Plot model comparison\n",
    "metrics_comparison = pd.DataFrame({\n",
    "    'Logistic Regression': lr_metrics,\n",
    "    'Random Forest': rf_metrics\n",
    "})\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "metrics_comparison.T.plot(kind='bar', ax=ax)\n",
    "ax.set_title('Model Performance Comparison')\n",
    "ax.set_ylabel('Score')\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=0)\n",
    "ax.legend(loc='lower right')\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nMetrics Comparison:\")\n",
    "print(metrics_comparison)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36aac7d7",
   "metadata": {},
   "source": [
    "## 7. Making Predictions on New Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904344b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Make prediction for a single patient\n",
    "patient_data = pd.DataFrame({\n",
    "    'Pregnancies': [6],\n",
    "    'Glucose': [148],\n",
    "    'BloodPressure': [72],\n",
    "    'SkinThickness': [35],\n",
    "    'Insulin': [0],\n",
    "    'BMI': [33.6],\n",
    "    'DiabetesPedigreeFunction': [0.627],\n",
    "    'Age': [50]\n",
    "})\n",
    "\n",
    "# Scale the patient data\n",
    "patient_scaled = scaler.transform(patient_data)\n",
    "\n",
    "# Make prediction using both models\n",
    "lr_prediction = lr_model.predict(patient_scaled)[0]\n",
    "rf_prediction = rf_model.predict(patient_scaled)[0]\n",
    "\n",
    "lr_probability = lr_model.predict_proba(patient_scaled)[0]\n",
    "rf_probability = rf_model.predict_proba(patient_scaled)[0]\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"PATIENT DATA:\")\n",
    "print(\"=\"*60)\n",
    "for col in patient_data.columns:\n",
    "    print(f\"  {col:25s}: {patient_data[col].values[0]:>8.2f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"PREDICTION RESULTS:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\nLogistic Regression:\")\n",
    "print(f\"  Prediction:              {'POSITIVE (Diabetes)' if lr_prediction == 1 else 'NEGATIVE (No Diabetes)'}\")\n",
    "print(f\"  Confidence:              {lr_probability[lr_prediction]*100:.2f}%\")\n",
    "print(f\"  Diabetes Probability:    {lr_probability[1]*100:.2f}%\")\n",
    "print(f\"  No Diabetes Probability: {lr_probability[0]*100:.2f}%\")\n",
    "\n",
    "print(\"\\nRandom Forest:\")\n",
    "print(f\"  Prediction:              {'POSITIVE (Diabetes)' if rf_prediction == 1 else 'NEGATIVE (No Diabetes)'}\")\n",
    "print(f\"  Confidence:              {rf_probability[rf_prediction]*100:.2f}%\")\n",
    "print(f\"  Diabetes Probability:    {rf_probability[1]*100:.2f}%\")\n",
    "print(f\"  No Diabetes Probability: {rf_probability[0]*100:.2f}%\")\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39eb9695",
   "metadata": {},
   "source": [
    "## 8. Batch Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba5bfffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions for multiple patients\n",
    "multiple_patients = pd.DataFrame({\n",
    "    'Pregnancies': [6, 1, 8, 1, 0],\n",
    "    'Glucose': [148, 85, 183, 89, 137],\n",
    "    'BloodPressure': [72, 66, 64, 66, 40],\n",
    "    'SkinThickness': [35, 29, 0, 23, 35],\n",
    "    'Insulin': [0, 0, 0, 94, 168],\n",
    "    'BMI': [33.6, 26.6, 23.3, 28.1, 43.1],\n",
    "    'DiabetesPedigreeFunction': [0.627, 0.351, 0.672, 0.167, 2.288],\n",
    "    'Age': [50, 31, 32, 21, 33]\n",
    "})\n",
    "\n",
    "# Scale and predict\n",
    "scaled = scaler.transform(multiple_patients)\n",
    "rf_predictions = rf_model.predict(scaled)\n",
    "rf_probabilities = rf_model.predict_proba(scaled)\n",
    "\n",
    "# Display results\n",
    "results = pd.DataFrame({\n",
    "    'Prediction': ['POSITIVE' if p == 1 else 'NEGATIVE' for p in rf_predictions],\n",
    "    'Confidence': [f\"{max(prob)*100:.2f}%\" for prob in rf_probabilities],\n",
    "    'Diabetes_Risk': [f\"{prob[1]*100:.2f}%\" for prob in rf_probabilities]\n",
    "})\n",
    "\n",
    "print(\"\\nBATCH PREDICTIONS (Random Forest):\")\n",
    "print(\"\\n\" + results.to_string())\n",
    "print(f\"\\nTotal predictions: {len(results)}\")\n",
    "print(f\"Positive cases: {(rf_predictions == 1).sum()}\")\n",
    "print(f\"Negative cases: {(rf_predictions == 0).sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c19ea3",
   "metadata": {},
   "source": [
    "## 9. Feature Importance (Random Forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b37fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature importance\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Importance': rf_model.feature_importances_\n",
    "}).sort_values('Importance', ascending=False)\n",
    "\n",
    "print(\"\\nFeature Importance (Random Forest):\")\n",
    "print(feature_importance.to_string(index=False))\n",
    "\n",
    "# Plot feature importance\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(feature_importance['Feature'], feature_importance['Importance'], color='steelblue')\n",
    "plt.xlabel('Importance Score')\n",
    "plt.title('Random Forest Feature Importance')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nTop 3 Most Important Features:\")\n",
    "for idx, row in feature_importance.head(3).iterrows():\n",
    "    print(f\"  {row['Feature']:30s}: {row['Importance']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c8272d",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### How the Code Works:\n",
    "\n",
    "1. **Data Loading**: We load or create the diabetes dataset with 8 medical features\n",
    "2. **Preprocessing**: \n",
    "   - Handle missing values by filling with mean\n",
    "   - Split data into training (80%) and testing (20%)\n",
    "   - Scale features using StandardScaler for better model performance\n",
    "3. **Model Training**: Train two models - Logistic Regression and Random Forest\n",
    "4. **Evaluation**: Calculate metrics (Accuracy, Precision, Recall, F1) and confusion matrices\n",
    "5. **Prediction**: Make predictions on new patient data with probability scores\n",
    "6. **Feature Analysis**: Identify which features are most important for prediction\n",
    "\n",
    "### Key Output:\n",
    "- Both models provide diabetes predictions (0 = No diabetes, 1 = Diabetes)\n",
    "- Probability scores show confidence in predictions\n",
    "- Feature importance reveals that Glucose and BMI are top predictors\n",
    "- Models achieve ~80% accuracy on test data\n",
    "\n",
    "### How to Use:\n",
    "1. Replace synthetic data with real `diabetes.csv` from UCI repository\n",
    "2. Run each cell sequentially\n",
    "3. Use trained models for predictions on new patients\n",
    "4. Monitor model performance metrics over time"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
